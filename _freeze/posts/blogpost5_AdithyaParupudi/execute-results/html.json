{
  "hash": "2f52335a9035ef3c13661fa6aa731da2",
  "result": {
    "markdown": "---\ntitle: \"Blog 5 - More Topic Modelling\"\nauthor: \"Adithya Parupudi\"\ndesription: \"Topic modeling on politicians, actors, writers\"\ndate: \"11/27/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Adithya Parupudi\n---\n\n\n# Libraries\n\nReading in all the libraries :)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(stm)\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n# Reading Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset <- read_csv(\"./100FamousPeople_new.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 100 Columns: 10\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(8): people_names, peoples_title, content, from, to, profession, country... dbl\n(2): ...1, ...2\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n• `...1` -> `...2`\n```\n:::\n\n```{.r .cell-code}\nhead(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 10\n   ...1  ...2 people_names    peopl…¹ content from  to    profe…² country gender\n  <dbl> <dbl> <chr>           <chr>   <chr>   <chr> <chr> <chr>   <chr>   <chr> \n1     1     1 Abraham Lincoln us pre… “With … 1809   1865 politi… america male  \n2     2     2 Adolf Hitler    leader… Adolf … 1889   1945 politi… germany male  \n3     3     3 Albert Einstein german… Born i… 1879   1955 academ… germany male  \n4     4     4 Alfred Hitchco… englis… Sir Al… 4      40   entert… america male  \n5     5     5 Amelia Earhart… aviator Amelia… 1897  1937  others  others  female\n6     6     6 Angelina Jolie  actres… Angeli… 1975  2022  entert… others  female\n# … with abbreviated variable names ¹​peoples_title, ²​profession\n```\n:::\n:::\n\n\n# To find similarity in Politician\n\nIn this blogpost, I will explore on the similarities between politicians of three countries that interested me. They are America (USA), India and Russia. I have studied about these countries a lot over these years and thought it would be interesting to search for similarities between people originating from these places. \n\n## Creating new var for America, Russia and India\nDefined three variables by filtering the data set with two filters, i.e., by country(ind, russia, usa) and by profession ( politician)\n\n::: {.cell}\n\n```{.r .cell-code}\npolitician_ind <- dataset %>%\n  filter(profession == \"politician\") %>%\n  filter(country == \"india\")\n\npolitician_america <- dataset %>%\n  filter(profession == \"politician\") %>%\n  filter(country == \"america\")\n\npolitician_russia <- dataset %>%\n  filter(profession == \"politician\") %>%\n  filter(country == \"russia\")\n```\n:::\n\n\n\n\n# Indian politicians\nPerforming data preprocessing by removing stop words, punctuation, converting to lowercase, and stemming words. Using the prepDocuments() function as a base to run an STM with K = 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolitician_ind_processed <- textProcessor(\n  documents = politician_ind$content,\n  metadata = politician_ind,\n  lowercase = T,\n  removestopwords = T,\n  removenumbers = T,\n  removepunctuation = T,\n  stem = T,\n  wordLengths = c(3, Inf),\n  language = \"en\",\n  onlycharacter = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n```\n:::\n\n```{.r .cell-code}\npolitician_ind_prepped <- prepDocuments(\n  documents = politician_ind_processed$documents,\n  vocab = politician_ind_processed$vocab,\n  meta = politician_ind_processed$meta,\n  lower.thresh = 2,\n  upper.thresh = Inf\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRemoving 813 of 858 terms (968 of 1103 tokens) due to frequency \nYour corpus now has 3 documents, 45 terms and 135 tokens.\n```\n:::\n\n```{.r .cell-code}\npolitician_ind_basicmodel <- stm(\n  documents = politician_ind_prepped$documents,\n  vocab = politician_ind_prepped$vocab,\n  data = politician_ind_prepped$meta,\n  K = 5,\n  verbose = F\n)\n```\n:::\n\n\n## Errors with searchK()\nWhile I am trying to use searchK() to find the optimal k value, I am getting an error. I have tweaked this function in multiple ways but there was no result. From what I understood through experimenting is, searchK() only works when the data set is high in number. \n\nSince I filtered the dataset(using multiple filters), each scenario has utmost 4 rows worth of information which is too low for searchK to provide any insights on this. \n\nSo throughout this blogpost, I will select K value based on experimentation. The best k value, according to me is, the uniqueness of words in each topic. If I am seeing more unique words in each topic, then the corresponding 'k' is good. \n\n::: {.cell}\n\n```{.r .cell-code}\nsearchK(politician_ind_processed$documents,\n  politician_ind_processed$vocab,\n  K = c(2, 5),\n  data = politician_ind_processed$meta,\n  verbose = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in stm(documents = heldout$documents, vocab = heldout$vocab, K = k, :\nK=2 is equivalent to a unidimensional scaling model which you may prefer.\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in missing$docs[[i]]: subscript out of bounds\n```\n:::\n:::\n\n\n## Indian politician topics\n\nPlotting the Indian politician topics with K = 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.STM(politician_ind_basicmodel)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n## Indian correlations\n\nToipcs (4,3) and (2,5) are correlated\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(topicCorr(politician_ind_basicmodel))\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## Topic 2 word cloud\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncloud(\n  stmobj = politician_ind_basicmodel,\n  topic = 2,\n  random.order = F,\n  rot.per = 0\n)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n## Topic 5 word cloud\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncloud(\n  stmobj = politician_ind_basicmodel,\n  topic = 5,\n  random.order = F,\n  rot.per = 0\n)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n# Russian politicans\nPerforming data preprocessing by removing stop words, punctuation, converting to lowercase, and stemming words. Using the prepDocuments() function as a base to run an STM with K = 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolitician_russia_processed <- textProcessor(\n  documents = politician_russia$content,\n  metadata = politician_russia,\n  lowercase = T,\n  removestopwords = T,\n  removenumbers = T,\n  removepunctuation = T,\n  stem = T,\n  wordLengths = c(3, Inf),\n  language = \"en\",\n  onlycharacter = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n```\n:::\n\n```{.r .cell-code}\npolitician_russia_prepped <- prepDocuments(\n  documents = politician_russia_processed$documents,\n  vocab = politician_russia_processed$vocab,\n  meta = politician_russia_processed$meta,\n  lower.thresh = 2,\n  upper.thresh = Inf\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRemoving 1012 of 1125 terms (1208 of 1572 tokens) due to frequency \nYour corpus now has 4 documents, 113 terms and 364 tokens.\n```\n:::\n\n```{.r .cell-code}\npolitician_russia_basicmodel <- stm(\n  documents = politician_russia_prepped$documents,\n  vocab = politician_russia_prepped$vocab,\n  data = politician_russia_prepped$meta,\n  K = 5,\n  verbose = F\n)\n```\n:::\n\n\n## Russian Topic Models\nPrinting topics\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.STM(politician_russia_basicmodel)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n## Russian Correlations\nWe can see correlation between topic 1 and 5\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(topicCorr(politician_russia_basicmodel))\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n## Russian word cloud\n\n::: {.cell}\n\n```{.r .cell-code}\ncloud(\n  stmobj = politician_russia_basicmodel,\n  topic = 1,\n  random.order = F,\n  rot.per = 0\n)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n# America politician\nPerforming data preprocessing by removing stop words, punctuation, converting to lowercase, and stemming words. Using the prepDocuments() function as a base to run an STM with K = 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolitician_america_processed <- textProcessor(\n  documents = politician_america$content,\n  metadata = politician_america,\n  lowercase = T,\n  removestopwords = T,\n  removenumbers = T,\n  removepunctuation = T,\n  stem = T,\n  wordLengths = c(3, Inf),\n  language = \"en\",\n  onlycharacter = T\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n```\n:::\n\n```{.r .cell-code}\npolitician_america_prepped <- prepDocuments(\n  documents = politician_america_processed$documents,\n  vocab = politician_america_processed$vocab,\n  meta = politician_america_processed$meta,\n  lower.thresh = 2,\n  upper.thresh = Inf\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRemoving 2445 of 3068 terms (2988 of 5749 tokens) due to frequency \nYour corpus now has 10 documents, 623 terms and 2761 tokens.\n```\n:::\n\n```{.r .cell-code}\npolitician_america_basicmodel <- stm(\n  documents = politician_america_prepped$documents,\n  vocab = politician_america_prepped$vocab,\n  data = politician_america_prepped$meta,\n  K = 6,\n  verbose = F\n)\n```\n:::\n\n\n## America Topics\nTopic 6 is talking about presidents, war and economy which sort of summarises all the topics here. The famous politicians from america are all presidents. During each term there was an internal or external strife which they worked very hard to deal with. \n\n::: {.cell}\n\n```{.r .cell-code}\nplot.STM(politician_america_basicmodel)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n## Plotting correlation\nLooks like no observations are related\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(topicCorr(politician_america_basicmodel))\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n## America- Word clouds \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncloud(\n  stmobj = politician_america_basicmodel,\n  topic = 1,\n  random.order = F,\n  rot.per = 0\n)\n```\n\n::: {.cell-output-display}\n![](blogpost5_AdithyaParupudi_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n# Interpretation so far\n\nWith what we have observed so far, here are my interepretations.\n\nRussia : Its is centered towards governance, war, communism, revolution, power. These words paint a picture of an internal power struggle ( Lenin vs Stalin) and the feelings associated with it. Germany, because of Karl Marx and WW2. This is the time when there were major changes started happening internally where they were deciding on power distribution. Later on, communism & nuclear disarmament happened.\n\nIndia : Here the focus is on Indian independence movement, where Gandhi was the most important figure. This word cloud tells me the struggles, death, protests, imprisonment during the freedom struggle.\n\nAmerica : Since the list is almost entirely made of presidents, the theme here is ‘Reforming America’. It captures the struggles each one faced w.r.t to elections, internal affairs, wars, civil movements. This tells the story of the politicians’ struggle to maintain peace both in locally and internationally.\n\n\n# Future Analysis\n\nTo perform similarity check on artists from Britain, USA and Europe\n\n\n\n\n\n",
    "supporting": [
      "blogpost5_AdithyaParupudi_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
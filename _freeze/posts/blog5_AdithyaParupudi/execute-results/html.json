{
  "hash": "07adefeeb562ff020f69ab8b36ad53bc",
  "result": {
    "markdown": "---\ntitle: \"Topic Modelling\"\nauthor: \"Adithya Parupudi\"\ndesription: \"Topic Modeling attempt\"\ndate: \"10/11/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Adithya Parupudi\n---\n\n\n# Libraries\n\nReading in all the libraries :)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(quanteda)\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(tokenizers)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(wordcloud2)\nlibrary(stopwords)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(ggplot2)\nknitr::opts_chunk$set(echo=TRUE)\n```\n:::\n\n\n\n# Reading Data\n\n### **From CSV**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset2 <- read_csv(\"./100FamousPeople_new.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 100 Columns: 10\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(8): people_names, peoples_title, content, from, to, profession, country... dbl\n(2): ...1, ...2\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n• `...1` -> `...2`\n```\n:::\n\n```{.r .cell-code}\nhead(dataset2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 10\n   ...1  ...2 people_names    peopl…¹ content from  to    profe…² country gender\n  <dbl> <dbl> <chr>           <chr>   <chr>   <chr> <chr> <chr>   <chr>   <chr> \n1     1     1 Abraham Lincoln us pre… “With … 1809   1865 politi… america male  \n2     2     2 Adolf Hitler    leader… Adolf … 1889   1945 politi… germany male  \n3     3     3 Albert Einstein german… Born i… 1879   1955 academ… germany male  \n4     4     4 Alfred Hitchco… englis… Sir Al… 4      40   entert… america male  \n5     5     5 Amelia Earhart… aviator Amelia… 1897  1937  others  others  female\n6     6     6 Angelina Jolie  actres… Angeli… 1975  2022  entert… others  female\n# … with abbreviated variable names ¹​peoples_title, ²​profession\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset2<- tibble(dataset2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# counting number of words each row\n\nstr_count(dataset2$content, '\\\\s+')+1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1]  1763  1000  1700  1192  1333  1378  1245  1481  1434   625  1387   386\n [13]   656   535   888   770   803   923  1019   783  1262   643   958  1319\n [25]  8333  1074   563  1652  1115  1343  1667  1738  1088  2038   896  1328\n [37]  1678  1707  1025   943   801 11039  1429  1330  1242   904   754  4856\n [49]  1265  1650  1925  1085   743  1264   740  1134  1374  1594   446   769\n [61]  1268  1059   807   643   880  1022   913  1630  1057  2553  1078  1469\n [73]  1023  1128   929   810  1090   903  1244  1515  1150  1224  1043  1116\n [85]  1323   875  1995  2082  1527  1257   671  1275  8389  1296  1398  1259\n [97]  1252  1545  1609   891\n```\n:::\n:::\n\n# Using STM\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_dataset <- dataset2 %>% \n  mutate(line=row_number()) %>%  # adding row number\n  unnest_tokens(word, content) %>%  # tokenising content column to a 'word' column\n  anti_join(stop_words) #removing stop words \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"word\"\n```\n:::\n\n```{.r .cell-code}\ntidy_dataset %>% count(word, sort=TRUE) # countind word frequency in the tidy_dataset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15,576 × 2\n   word          n\n   <chr>     <int>\n 1 world       334\n 2 time        304\n 3 war         302\n 4 biden       276\n 5 life        250\n 6 people      241\n 7 musk        227\n 8 woods       211\n 9 president   166\n10 american    141\n# … with 15,566 more rows\n```\n:::\n:::\n\n\n## Exploring tf-idf\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_dataset %>% \n  count(people_names, word, sort=TRUE) %>% \n  bind_tf_idf(word,people_names,n) %>% \n  group_by(people_names) %>% \n  top_n(10) %>% \n  ungroup() %>% \n  mutate(word=reorder(word,tf_idf)) %>% \n  filter(., people_names=='Muhammad Ali' | people_names=='Lionel Messi' | people_names=='Nelson Mandela')  %>% \n  ggplot(aes(word,tf_idf, fill=people_names)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~people_names, scales=\"free\") +\n  coord_flip() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by tf_idf\n```\n:::\n\n::: {.cell-output-display}\n![](blog5_AdithyaParupudi_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n# explore topic modeling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stm' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstm v1.3.6 successfully loaded. See ?stm for help. \n Papers, resources, and other materials at structuraltopicmodel.com\n```\n:::\n\n```{.r .cell-code}\ntidy_dfm <- tidy_dataset %>% \n  count(people_names, word, sort=TRUE) %>% \n  cast_dfm(people_names, word, n)\n\ntopic_model <- stm(tidy_dfm, K = 6, init.type = 'Spectral')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBeginning Spectral Initialization \n\t Calculating the gram matrix...\n\t Using only 10000 most frequent terms during initialization...\n\t Finding anchor words...\n \t......\n\t Recovering initialization...\n \t....................................................................................................\nInitialization complete.\n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 1 (approx. per word bound = -8.938) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 2 (approx. per word bound = -8.038, relative change = 1.006e-01) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 3 (approx. per word bound = -7.916, relative change = 1.523e-02) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 4 (approx. per word bound = -7.895, relative change = 2.590e-03) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 5 (approx. per word bound = -7.890, relative change = 6.753e-04) \nTopic 1: life, pope, time, john, world \n Topic 2: musk, tesla, company, time, queen \n Topic 3: biden, president, ali, rights, obama \n Topic 4: woods, kardashian, golf, time, tour \n Topic 5: world, record, messi, cup, time \n Topic 6: war, world, people, soviet, party \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 6 (approx. per word bound = -7.887, relative change = 3.098e-04) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 7 (approx. per word bound = -7.886, relative change = 1.745e-04) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 8 (approx. per word bound = -7.885, relative change = 9.244e-05) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 9 (approx. per word bound = -7.885, relative change = 5.568e-05) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 10 (approx. per word bound = -7.885, relative change = 3.745e-05) \nTopic 1: life, pope, time, world, john \n Topic 2: musk, tesla, company, time, queen \n Topic 3: biden, president, ali, rights, obama \n Topic 4: woods, kardashian, golf, time, tour \n Topic 5: world, record, messi, beatles, time \n Topic 6: war, world, people, soviet, party \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 11 (approx. per word bound = -7.884, relative change = 2.032e-05) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nCompleting Iteration 12 (approx. per word bound = -7.884, relative change = 1.089e-05) \n....................................................................................................\nCompleted E-Step (0 seconds). \nCompleted M-Step. \nModel Converged \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(topic_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA topic model with 6 topics, 100 documents and a 15576 word dictionary.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTopic 1 Top Words:\n \t Highest Prob: life, pope, time, world, john, freud, people \n \t FREX: freud, vinci, wilde, columbus, gogh, teresa, tolstoy \n \t Lift: 1886, disciples, discovery, diseases, edwards, j.k, papacy \n \t Score: freud, vinci, da, pope, beethoven, wilde, gogh \nTopic 2 Top Words:\n \t Highest Prob: musk, tesla, company, time, queen, film, prince \n \t FREX: musk, plato, audrey, spacex, musk's, cleopatra, socrates \n \t Lift: actresses, æ, architecture, ashlee, attendant, ballet, billionaires \n \t Score: musk, tesla, spacex, plato, musk's, audrey, prince \nTopic 3 Top Words:\n \t Highest Prob: biden, president, ali, rights, obama, american, people \n \t FREX: biden's, malala, montgomery, thunberg, racial, biden, ali \n \t Lift: 2030, 46th, aftermath, anders, appeals, appointments, atlanta \n \t Score: biden, biden's, senate, obama, malala, parks, vice \nTopic 4 Top Words:\n \t Highest Prob: woods, kardashian, golf, time, tour, career, world \n \t FREX: kardashian, golf, pga, apple, tiger, woods's, monroe \n \t Lift: accenture, anaheim, apprentice, baker, barriers, beach, bergman’s \n \t Score: kardashian, woods, golf, pga, tiger, woods's, apple \nTopic 5 Top Words:\n \t Highest Prob: world, record, messi, beatles, time, lennon, cup \n \t FREX: messi, ruth, babe, branson, jordan, pele, beckham \n \t Lift: athletics, brazilian, bulls, matthias, ruth’s, sox, 09 \n \t Score: messi, ruth, babe, branson, jordan, bolt, pele \nTopic 6 Top Words:\n \t Highest Prob: war, world, people, soviet, party, life, government \n \t FREX: einstein, lenin, thatcher, stalin, chanel, keynes, picasso \n \t Lift: 1883, acquainted, armies, armistice, atomic, benazir, biographers \n \t Score: soviet, lenin, einstein, gorbachev, reagan, thatcher, stalin \n```\n:::\n:::\n\n## Beta matrix\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_beta <- tidy(topic_model)\n\ntidy_beta %>% group_by(topic) %>% \n  top_n(10) %>% \n  ungroup() %>% \n  mutate(term=reorder(term,beta)) %>% \n  ggplot(aes(term,beta, fill=topic)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~topic, scales=\"free\") +\n  coord_flip() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by beta\n```\n:::\n\n::: {.cell-output-display}\n![](blog5_AdithyaParupudi_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n# using Gamma matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_gamma <- tidy(topic_model, matrix=\"gamma\", document_names = rownames(tidy_dfm))\n\n\nggplot(tidy_gamma, aes(gamma, fill = as.factor(topic)))+\n  geom_histogram(show.legend = FALSE)+\n  facet_wrap(~topic, ncol=3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](blog5_AdithyaParupudi_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "blog5_AdithyaParupudi_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}